{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c8be179",
   "metadata": {},
   "source": [
    "### What we used \n",
    "\n",
    "1. df.head() , df.info() , df.describe()  -> To inspect data\n",
    "2. df.skew(numeric_only=True) - To check skweness of each coulmn. it use (Fisher-Pearson standardized)\n",
    "3. df[df.duplicated()] -> To check duplicatae value\n",
    "4. df.isnull().sum() -> To check null value\n",
    "5. df['ID'].unique()  -> To check unique value in a perticular coulmn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96a7753",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "ebe042ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Email</th>\n",
       "      <th>Phone</th>\n",
       "      <th>JoinDate</th>\n",
       "      <th>LastLogin</th>\n",
       "      <th>Age</th>\n",
       "      <th>Country</th>\n",
       "      <th>Category</th>\n",
       "      <th>Qty</th>\n",
       "      <th>Price</th>\n",
       "      <th>Total</th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Returned</th>\n",
       "      <th>VIP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Alice</td>\n",
       "      <td>alice@mail.com</td>\n",
       "      <td>123-456-7890</td>\n",
       "      <td>01/05/2025</td>\n",
       "      <td>2025-05-02 10:00</td>\n",
       "      <td>25</td>\n",
       "      <td>USA</td>\n",
       "      <td>Widgets</td>\n",
       "      <td>3.0</td>\n",
       "      <td>19.99</td>\n",
       "      <td>59.97</td>\n",
       "      <td>Love it!</td>\n",
       "      <td>5.0</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Bob</td>\n",
       "      <td>bob AT mail.com</td>\n",
       "      <td>123456789</td>\n",
       "      <td>2025/01/06</td>\n",
       "      <td>06-01-2025</td>\n",
       "      <td>30</td>\n",
       "      <td>United States</td>\n",
       "      <td>gadgets</td>\n",
       "      <td>1.0</td>\n",
       "      <td>49.5</td>\n",
       "      <td>49.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Charlie</td>\n",
       "      <td>charlie@mail.com</td>\n",
       "      <td>(123)456-7890</td>\n",
       "      <td>05-01-2025</td>\n",
       "      <td>2025/01/05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>widget a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ok</td>\n",
       "      <td>3.0</td>\n",
       "      <td>no</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Alice</td>\n",
       "      <td>alice@mail.com</td>\n",
       "      <td>123-456-7890</td>\n",
       "      <td>1-5-2025</td>\n",
       "      <td>05-01-2025</td>\n",
       "      <td>25</td>\n",
       "      <td>USA</td>\n",
       "      <td>Widgets</td>\n",
       "      <td>3.0</td>\n",
       "      <td>19.99</td>\n",
       "      <td>59.97</td>\n",
       "      <td>love it!</td>\n",
       "      <td>5.0</td>\n",
       "      <td>no</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Dana</td>\n",
       "      <td>NaN</td>\n",
       "      <td>123-456</td>\n",
       "      <td>07/02/2025</td>\n",
       "      <td>2025/02/07</td>\n",
       "      <td>40</td>\n",
       "      <td>UK</td>\n",
       "      <td>Things</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>bad quality</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID     Name             Email          Phone    JoinDate         LastLogin  \\\n",
       "0   1    Alice    alice@mail.com   123-456-7890  01/05/2025  2025-05-02 10:00   \n",
       "1   2      Bob   bob AT mail.com      123456789  2025/01/06        06-01-2025   \n",
       "2   3  Charlie  charlie@mail.com  (123)456-7890  05-01-2025        2025/01/05   \n",
       "3   1    Alice    alice@mail.com   123-456-7890    1-5-2025        05-01-2025   \n",
       "4   4     Dana               NaN        123-456  07/02/2025        2025/02/07   \n",
       "\n",
       "   Age        Country  Category  Qty  Price  Total       Review  Rating  \\\n",
       "0   25            USA   Widgets  3.0  19.99  59.97     Love it!     5.0   \n",
       "1   30  United States   gadgets  1.0   49.5   49.5          NaN     NaN   \n",
       "2  NaN             US  widget a  NaN  19.99    NaN           ok     3.0   \n",
       "3   25            USA   Widgets  3.0  19.99  59.97     love it!     5.0   \n",
       "4   40             UK    Things  2.0      5     10  bad quality     1.0   \n",
       "\n",
       "  Returned    VIP  \n",
       "0       No    Yes  \n",
       "1    False  False  \n",
       "2       no    Yes  \n",
       "3       no    Yes  \n",
       "4      Yes     No  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset and get an overview\n",
    "df = pd.read_csv('cleaned_data.csv')\n",
    "\n",
    "#step 2:- Get an overview of the dataset or inspect the data\n",
    "\n",
    "#head() Display the first few rows of the dataset, #default is 5 rows, if we want to see more we can write data.head(10) for 10 rows\n",
    "df.head() \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "f8acc387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 16 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   ID         10 non-null     int64  \n",
      " 1   Name       10 non-null     object \n",
      " 2   Email      9 non-null      object \n",
      " 3   Phone      9 non-null      object \n",
      " 4   JoinDate   10 non-null     object \n",
      " 5   LastLogin  10 non-null     object \n",
      " 6   Age        9 non-null      object \n",
      " 7   Country    10 non-null     object \n",
      " 8   Category   10 non-null     object \n",
      " 9   Qty        9 non-null      float64\n",
      " 10  Price      9 non-null      object \n",
      " 11  Total      8 non-null      object \n",
      " 12  Review     9 non-null      object \n",
      " 13  Rating     8 non-null      float64\n",
      " 14  Returned   8 non-null      object \n",
      " 15  VIP        9 non-null      object \n",
      "dtypes: float64(2), int64(1), object(13)\n",
      "memory usage: 1.4+ KB\n"
     ]
    }
   ],
   "source": [
    "#info() gives us the data types of each column and non-null counts\n",
    "\n",
    "#non-null count- How many non-missing values there are in this column.\n",
    "#data types- The type of data in each column (like int, float, object, etc.)\n",
    "df.info() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "0585f8c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Qty</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.600000</td>\n",
       "      <td>6.220000</td>\n",
       "      <td>3.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.875181</td>\n",
       "      <td>12.748553</td>\n",
       "      <td>1.505941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.750000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>39.980000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ID        Qty    Rating\n",
       "count  10.000000   9.000000  8.000000\n",
       "mean    4.600000   6.220000  3.625000\n",
       "std     2.875181  12.748553  1.505941\n",
       "min     1.000000   0.000000  1.000000\n",
       "25%     2.250000   1.000000  2.750000\n",
       "50%     4.500000   2.000000  4.000000\n",
       "75%     6.750000   3.000000  5.000000\n",
       "max     9.000000  39.980000  5.000000"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#describe() gives us summary statistics for numerical columns(like mean, std, min, max, etc.)\n",
    "\n",
    "#count- How many non-missing values there are in this column. it tells total number of columns are there and how many of them are missing values.\n",
    "#mean= The average (mean) value of the each column.\n",
    "#std= How spread out the numbers are from the mean.\n",
    " #example:-\n",
    "  #Rating column data:- \n",
    "    #Mean (average) = 3.625\n",
    "    #Std = 1.505  (std formula is sqrt(sum((x - mean)^2) / n) where x is each value, mean is the average, and n is the number of values.)\n",
    "        #Lower bound = 3.625(mean) âˆ’ 1.505(std) â‰ˆ 2.12\n",
    "        #Upper bound = 3.625(mean) + 1.505(std) â‰ˆ 5.13\n",
    "        #So, most ratings are likely between 2.12 and 5.13, Rating outside this range 2.12 and 5.13  â†’ is potential outlier\n",
    "        # |----2.12----Mean=3.625----5.13----|\n",
    "\n",
    "        # over all summmary of std is  :- Smaller std â†’ ratings very close to mean â†’ consistent customer feedback and Larger std â†’ ratings very different â†’ inconsistent feedback, it indicates that customers have varying opinions about the product or service.\n",
    "#25% (First Quartile / Q1)- The value below which 25% of the data falls.\n",
    "#50% (Median / Q2)- The middle value of the data when sorted.\n",
    "#75% (Third Quartile / Q3)- The value below which 75% of the data falls.\n",
    "#min- The smallest value in the column.\n",
    "#max- The largest value in the column.\n",
    "df.describe() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "ae318716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID        0.151463\n",
      "Qty       2.921639\n",
      "Rating   -0.820896\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# check skewness of the data\n",
    "\n",
    "#skewness- It measures the asymmetry of the data distribution.\n",
    "#skewness > 0 â†’ right-skewed (long tail on the right)\n",
    "#skewness < 0 â†’ left-skewed (long tail on the left)\n",
    "#skewness = (mean - median) / std\n",
    "#skewness = 3.625(mean) - 3.0(median) / 1.505(std) â‰ˆ 0.42\n",
    "#Since skewness is positive (0.42), the ratings are slightly right-skewed, indicating that there are more ratings above the mean than below it, but the distribution is not highly skewed.\n",
    "\n",
    "#it shows that the ratings are slightly right-skewed, with more ratings above the mean (3.625) than below it, but the distribution is not highly skewed.\n",
    "# for all the columns we can check skewness by using skew() function\n",
    "skewness = df.skew(numeric_only=True)\n",
    "print(skewness) \n",
    "\n",
    "#if skewness value is greater than 1 or less than -1 then we can say that the data is highly skewed.\n",
    "\n",
    "#how calulate skewness  value using pandas skew() function\n",
    "#skewness = df['Rating'].skew() for perticular column\n",
    "#print(skewness)\n",
    "\n",
    "#what formula is used to calculate skewness in pandas skew() function?\n",
    "#Pandas uses the Fisher-Pearson standardized moment coefficient formula to calculate skewness.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "c2b76ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step1:-  handle duplicates\n",
    "#show duplicate rows\n",
    "df[df.duplicated()]\n",
    "\n",
    "#drop duplicate rows\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1d65d5",
   "metadata": {},
   "source": [
    "### Step 1: Remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "e1c85400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID           0\n",
       "Name         0\n",
       "Email        1\n",
       "Phone        1\n",
       "JoinDate     0\n",
       "LastLogin    0\n",
       "Age          1\n",
       "Country      0\n",
       "Category     0\n",
       "Qty          1\n",
       "Price        1\n",
       "Total        2\n",
       "Review       1\n",
       "Rating       2\n",
       "Returned     2\n",
       "VIP          1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#step1:- check duplicate with column ID because ID column should be unique for each customer, if we have duplicate values in ID column it means we have duplicate rows in our dataset.\n",
    "\n",
    "#check duplicate values in ID column\n",
    "df[df.duplicated(subset=['ID'], keep=False)]  #if a column have duplicate , it will also bring with whome it is duplicated . keep=False will show all the duplicate rows, including the original and the duplicates. \n",
    "\n",
    "#drop the duplicate rows based on ID column\n",
    "df.drop_duplicates(subset=['ID'], inplace=True)\n",
    "\n",
    " # check distinct values in ID column\n",
    "df['ID'].unique()\n",
    "\n",
    "#checked missing values, No missing values found  in clomn ID\n",
    "df.isnull().sum()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ff532a",
   "metadata": {},
   "source": [
    "### Step 2: Fix emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "7ca96924",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l5/brjnv_593qdf8cbh4v4ch0840000gn/T/ipykernel_24193/3680817775.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Email'].fillna('NO mail', inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['alice@mail.com', 'bob@mail.com', 'charlie@mail.com', 'No mail',\n",
       "       'ernie@mail.com', 'frank@mail.com', 'henry@mail.com',\n",
       "       'ida@mail.com'], dtype=object)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "#step 3:- Identify and handle missing values\n",
    "#check missing values\n",
    "df.isnull().sum()\n",
    "\n",
    "#fix missing value in email column by filling with 'NO mail'\n",
    "df['Email'].fillna('NO mail', inplace=True)\n",
    "\n",
    "#check distinct values in email column\n",
    "df['Email'].unique() \n",
    "\n",
    "#Found different one formate incorrect email ids  \" 'bob AT mail.com', 'carol.mail.com', 'dave@mail', 'eve@mail..com' \"\n",
    "def clean_email(email):\n",
    "    if pd.isna(email):  #isna() function is used to check if the value is missing (NaN) or not. It returns True if the value is NaN and False otherwise.\n",
    "        return np.nan\n",
    "    \n",
    "    email = email.lower().strip()\n",
    "    email = email.replace(' at ', '@')\n",
    "    email = email.replace('..', '.')\n",
    "    \n",
    "    pattern = r'^[a-z0-9._%+-]+@[a-z0-9.-]+\\.[a-z]{2,}$'  #regex pattern for valid email address\n",
    "    return email if pd.Series(email).str.match(pattern)[0] else 'No mail'  # will replace nan with 'No mail' if the email is invalid\n",
    "\n",
    "df['Email'] = df['Email'].apply(clean_email)\n",
    "\n",
    "\n",
    "df['Email'].unique()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c032e6",
   "metadata": {},
   "source": [
    "### Step 3:Fix phone numbers (pending)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "2d663274",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l5/brjnv_593qdf8cbh4v4ch0840000gn/T/ipykernel_24193/4186202431.py:52: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Phone'].fillna('No phone', inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ID           0\n",
       "Name         0\n",
       "Email        0\n",
       "Phone        0\n",
       "JoinDate     0\n",
       "LastLogin    0\n",
       "Age          1\n",
       "Country      0\n",
       "Category     0\n",
       "Qty          1\n",
       "Price        1\n",
       "Total        2\n",
       "Review       1\n",
       "Rating       2\n",
       "Returned     2\n",
       "VIP          1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#step 3:- Identify and handle missing values\n",
    "#check missing values\n",
    "df.isnull().sum()\n",
    "\n",
    "#check distinct values in phone number column\n",
    "df['Phone'].unique()\n",
    "\n",
    "#found one formate of incorrect phone number \" 123-456-7890', '123456789', '(123)456-7890', '123-456', '+44 123 456 789', '2025-07-04', nan \"\n",
    "\n",
    "#Step1: Convert to string safely.it wll Prevents errors during string operations.\n",
    "\n",
    "df['Phone'] = df['Phone'].astype(str).str.strip()\n",
    "df['Phone'] = df['Phone'].replace('nan', np.nan)\n",
    "\n",
    "#step2: ðŸ”¹ Step 3.3: Remove unwanted characters (keep digits & +)\n",
    "df['Phone_clean'] = df['Phone'].str.replace(r'[^0-9+]', '', regex=True) # (123)456-7890 â†’ 1234567890, +44 123 456 789 â†’ +44123456789\n",
    "\n",
    "#Step 3: Remove date values wrongly stored as phone\n",
    "df['Phone_clean'] = df['Phone_clean'].where(\n",
    "    ~df['Phone_clean'].str.match(r'^20\\d{6}$', na=False)\n",
    "    \n",
    ")\n",
    "\n",
    "#step4: Step 3.5: Validate & format phone numbers (MAIN LOGIC)\n",
    "def format_phone(phone):\n",
    "    if pd.isna(phone):\n",
    "        return np.nan\n",
    "\n",
    "    # UK number\n",
    "    if phone.startswith('+44'):\n",
    "        digits = phone.replace('+44', '')\n",
    "        if 9 <= len(digits) <= 10:\n",
    "            return f'+44-{digits[:4]}-{digits[4:]}'\n",
    "        return np.nan\n",
    "\n",
    "    # US number\n",
    "    if phone.isdigit() and len(phone) == 10:\n",
    "        return f'+1-{phone[:3]}-{phone[3:6]}-{phone[6:]}'\n",
    "\n",
    "    return np.nan\n",
    "\n",
    "\n",
    "#Apply the formatting function to the cleaned phone numbers\n",
    "df['Phone'] = df['Phone_clean'].apply(format_phone)\n",
    "df.drop(columns='Phone_clean', inplace=True)\n",
    "\n",
    "df['Phone'].unique()\n",
    "\n",
    "df.isnull().sum()  # found 8 missing value\n",
    "\n",
    "#handle missing value in phone column by filling with 'No phone'\n",
    "df['Phone'].fillna('No phone', inplace=True)\n",
    "\n",
    "df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79475d5",
   "metadata": {},
   "source": [
    "### Step 4: Standardize dates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "95f57776",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l5/brjnv_593qdf8cbh4v4ch0840000gn/T/ipykernel_24193/947579494.py:30: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['JoinDate'].fillna('No date', inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ID              0\n",
       "Name            0\n",
       "Email           0\n",
       "Phone           0\n",
       "JoinDate        0\n",
       "LastLogin       0\n",
       "Age             1\n",
       "Country         0\n",
       "Category        0\n",
       "Qty             1\n",
       "Price           1\n",
       "Total           2\n",
       "Review          1\n",
       "Rating          2\n",
       "Returned        2\n",
       "VIP             1\n",
       "DaJoinDatete    7\n",
       "dtype: int64"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#step 3:- Identify and handle missing values\n",
    "#check missing values\n",
    "df.isnull().sum()\n",
    "\n",
    "#No missing values found in our dataset, so we can move to next step.\n",
    "\n",
    "#step 4: Standardize dates\n",
    "#check distinct values in date column\n",
    "df['JoinDate'].unique()\n",
    "\n",
    "# found different formate of incorrect date \" '2025-07-04', '2024/08/15', '15-09-2023', '2023.10.01', '2023-11-30', '2023/12/25' \"\n",
    "#standardize date format to YYYY-MM-DD\n",
    "\n",
    "#Step 1: Convert column to string safely. it will Avoid parsing errors when formats are mixed.\n",
    "df['JoinDate'] = df['JoinDate'].astype(str).str.strip()\n",
    "df['JoinDate'] = df['JoinDate'].replace('nan', pd.NaT)\n",
    "\n",
    "#Step 2: Parse dates with multiple formats\n",
    "df['JoinDate'] = pd.to_datetime( df['JoinDate'], errors='coerce', dayfirst=True) # dayfirst=True resolves ambiguity (05-01-2025 â†’ 5 Jan), Pandas automatically handles: 2025/01/06,2025-07-02,July 3, 2025\n",
    "\n",
    "#Step 3: Standardize display format (optional but recommended)\n",
    "df['JoinDate'] = df['JoinDate'].dt.strftime('%Y-%m-%d')  \n",
    "\n",
    "df['JoinDate'].unique()\n",
    "\n",
    "#check missing values\n",
    "df.isnull().sum()\n",
    "\n",
    "#handle missing values \n",
    "df['JoinDate'].fillna('No date', inplace=True)\n",
    "\n",
    "df.isnull().sum()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4188c6",
   "metadata": {},
   "source": [
    "### # Qty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "4ffbf2b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID              0\n",
       "Name            0\n",
       "Email           0\n",
       "Phone           0\n",
       "JoinDate        0\n",
       "LastLogin       0\n",
       "Age             1\n",
       "Country         0\n",
       "Category        0\n",
       "Qty             0\n",
       "Price           1\n",
       "Total           2\n",
       "Review          1\n",
       "Rating          2\n",
       "Returned        2\n",
       "VIP             1\n",
       "DaJoinDatete    7\n",
       "dtype: int64"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check missing values\n",
    "df.isnull().sum()\n",
    "\n",
    "#check unique values in Qty column\n",
    "df['Qty'].unique()\n",
    "\n",
    "#handle missing value \n",
    "df[\"Qty\"] = pd.to_numeric(df[\"Qty\"], errors=\"coerce\").fillna(0)\n",
    "\n",
    "df.isnull().sum()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf92a86",
   "metadata": {},
   "source": [
    "### #Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd73be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l5/brjnv_593qdf8cbh4v4ch0840000gn/T/ipykernel_24193/2814904854.py:15: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Price'].fillna(0, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([19.99, 49.5 ,  5.  ,  0.  , 12.  ])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#step 3:- Identify and handle missing values\n",
    "#check missing values\n",
    "df.isnull().sum()\n",
    "\n",
    "#check unique values in Price column\n",
    "df['Price'].unique()\n",
    "\n",
    "\n",
    "#handle missing value, found Non-numeric value abc in Price column\n",
    "df[\"Price\"] = pd.to_numeric(df[\"Price\"], errors=\"coerce\") #This will convert valid numbers to numeric and non-numeric values (like 'abc') to NaN.\n",
    "\n",
    "df['Price'].unique()\n",
    "\n",
    "#handle missing value by filling with 0\n",
    "df['Price'].fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a9625e",
   "metadata": {},
   "source": [
    "### #Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "dd7e872c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([59.97, 49.5 ,  0.  , 10.  , 60.  ])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check missing values\n",
    "df.isnull().sum()\n",
    "\n",
    "#check unique values in Total column\n",
    "df['Total'].unique()\n",
    "\n",
    "#fond Missing and Incorrect values in Total column, found Non-numeric value 'xyz' in Total column\n",
    "df[\"Total\"] = pd.to_numeric(df[\"Total\"], errors=\"coerce\") #This will convert valid numbers to numeric and non-numeric values (like 'xyz') to NaN.\n",
    "df['Total'].unique()\n",
    "\n",
    "df[\"Total\"] = df[\"Qty\"] * df[\"Price\"]\n",
    "\n",
    "df['Total'].unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9425d87",
   "metadata": {},
   "source": [
    "### Review column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "d19b8d29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID              0\n",
       "Name            0\n",
       "Email           0\n",
       "Phone           0\n",
       "JoinDate        0\n",
       "LastLogin       0\n",
       "Age             1\n",
       "Country         0\n",
       "Category        0\n",
       "Qty             0\n",
       "Price           0\n",
       "Total           0\n",
       "Review          0\n",
       "Rating          2\n",
       "Returned        2\n",
       "VIP             1\n",
       "DaJoinDatete    7\n",
       "dtype: int64"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check missing values\n",
    "df.isnull().sum()\n",
    "\n",
    "#check unique values in Total column\n",
    "df['Review'].unique()\n",
    "\n",
    "#handle missing value by filling with 'No review'\n",
    "df['Review'].fillna('No review', inplace=True)\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4ae2b4",
   "metadata": {},
   "source": [
    "### Rating Coulmn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "6ac1d993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5., 4., 3., 1., 2.])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check missing values\n",
    "df.isnull().sum()\n",
    "\n",
    "#check unique values in Rating column\n",
    "df['Rating'].unique()\n",
    "\n",
    "# found missing values in Rating column, handle missing value by filling with mean rating\n",
    "df[\"Rating\"] = pd.to_numeric(df[\"Rating\"], errors=\"coerce\")\n",
    "df[\"Rating\"] = df[\"Rating\"].fillna(df[\"Rating\"].median()) #filling missing values with median is better than mean because median is less affected by outliers than mean.\n",
    "df['Rating'].unique()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78bc70b",
   "metadata": {},
   "source": [
    "### Returned column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "87cabd83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l5/brjnv_593qdf8cbh4v4ch0840000gn/T/ipykernel_24193/5803756.py:14: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Returned'].fillna('No', inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ID              0\n",
       "Name            0\n",
       "Email           0\n",
       "Phone           0\n",
       "JoinDate        0\n",
       "LastLogin       0\n",
       "Age             1\n",
       "Country         0\n",
       "Category        0\n",
       "Qty             0\n",
       "Price           0\n",
       "Total           0\n",
       "Review          0\n",
       "Rating          0\n",
       "Returned        0\n",
       "VIP             1\n",
       "DaJoinDatete    7\n",
       "dtype: int64"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check missing values\n",
    "df.isnull().sum()\n",
    "\n",
    "#check unique values in Total column\n",
    "df['Returned'].unique()\n",
    "\n",
    "#found missing values in \"No', 'False', 'no', 'Yes', 'false', nan, 'Y'\"\"\n",
    "#standardize values to 'Yes' and 'No'\n",
    "df['Returned'] = df['Returned'].str.strip().str.lower()  # Remove leading/trailing spaces and convert to lowercase\n",
    "df['Returned'] = df['Returned'].replace({'no': 'No', 'false': 'No', 'yes': 'Yes', 'y': 'Yes'})  # Standardize to 'Yes' and 'No'\n",
    "df['Returned'].unique()\n",
    "\n",
    "#handle missing value by filling with 'No'\n",
    "df['Returned'].fillna('No', inplace=True)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b776bdac",
   "metadata": {},
   "source": [
    "### VIP column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "f7777780",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l5/brjnv_593qdf8cbh4v4ch0840000gn/T/ipykernel_24193/917947371.py:15: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['VIP'].fillna('No', inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Yes', 'No'], dtype=object)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#step 3:- Identify and handle missing values\n",
    "#check missing values\n",
    "df.isnull().sum()\n",
    "\n",
    "#check unique values in Price column\n",
    "df['VIP'].unique()\n",
    "\n",
    "#found missing values in \"No', 'False', 'no', 'Yes', 'false', nan, 'Y'\"\"\n",
    "#standardize values to 'Yes' and 'No'\n",
    "df['VIP'] = df['VIP'].str.strip().str.lower()  # Remove leading/trailing spaces and convert to lowercase\n",
    "df['VIP'] = df['VIP'].replace({'no': 'No', 'false': 'No', 'true': 'Yes' ,'yes': 'Yes', 'y': 'Yes'})  # Standardize to 'Yes' and 'No'\n",
    "df['VIP'].unique()\n",
    "\n",
    "#handle missing value by filling with 'No'\n",
    "df['VIP'].fillna('No', inplace=True)\n",
    "df.isnull().sum()\n",
    "\n",
    "df['VIP'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0ef4e2",
   "metadata": {},
   "source": [
    "### Fimal validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "948fd339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 9 entries, 0 to 9\n",
      "Data columns (total 17 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   ID            9 non-null      int64  \n",
      " 1   Name          9 non-null      object \n",
      " 2   Email         9 non-null      object \n",
      " 3   Phone         9 non-null      object \n",
      " 4   JoinDate      9 non-null      object \n",
      " 5   LastLogin     9 non-null      object \n",
      " 6   Age           8 non-null      object \n",
      " 7   Country       9 non-null      object \n",
      " 8   Category      9 non-null      object \n",
      " 9   Qty           9 non-null      float64\n",
      " 10  Price         9 non-null      float64\n",
      " 11  Total         9 non-null      float64\n",
      " 12  Review        9 non-null      object \n",
      " 13  Rating        9 non-null      float64\n",
      " 14  Returned      9 non-null      object \n",
      " 15  VIP           9 non-null      object \n",
      " 16  DaJoinDatete  2 non-null      object \n",
      "dtypes: float64(4), int64(1), object(12)\n",
      "memory usage: 1.3+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ID              0\n",
       "Name            0\n",
       "Email           0\n",
       "Phone           0\n",
       "JoinDate        0\n",
       "LastLogin       0\n",
       "Age             1\n",
       "Country         0\n",
       "Category        0\n",
       "Qty             0\n",
       "Price           0\n",
       "Total           0\n",
       "Review          0\n",
       "Rating          0\n",
       "Returned        0\n",
       "VIP             0\n",
       "DaJoinDatete    7\n",
       "dtype: int64"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info()\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "6226d0ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 9 entries, 0 to 9\n",
      "Data columns (total 16 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   ID         9 non-null      int64  \n",
      " 1   Name       9 non-null      object \n",
      " 2   Email      9 non-null      object \n",
      " 3   Phone      9 non-null      object \n",
      " 4   JoinDate   9 non-null      object \n",
      " 5   LastLogin  9 non-null      object \n",
      " 6   Age        8 non-null      object \n",
      " 7   Country    9 non-null      object \n",
      " 8   Category   9 non-null      object \n",
      " 9   Qty        9 non-null      float64\n",
      " 10  Price      9 non-null      float64\n",
      " 11  Total      9 non-null      float64\n",
      " 12  Review     9 non-null      object \n",
      " 13  Rating     9 non-null      float64\n",
      " 14  Returned   9 non-null      object \n",
      " 15  VIP        9 non-null      object \n",
      "dtypes: float64(4), int64(1), object(11)\n",
      "memory usage: 1.2+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ID           0\n",
       "Name         0\n",
       "Email        0\n",
       "Phone        0\n",
       "JoinDate     0\n",
       "LastLogin    0\n",
       "Age          1\n",
       "Country      0\n",
       "Category     0\n",
       "Qty          0\n",
       "Price        0\n",
       "Total        0\n",
       "Review       0\n",
       "Rating       0\n",
       "Returned     0\n",
       "VIP          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove DaJoinDatete column\n",
    "#df.drop(columns=['DaJoinDatete'], inplace=True)\n",
    "\n",
    "df.info()\n",
    "df.isnull().sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
